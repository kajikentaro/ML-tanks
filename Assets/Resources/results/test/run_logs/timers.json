{
    "name": "root",
    "gauges": {
        "TankA2.Policy.Entropy.mean": {
            "value": 3.5959208011627197,
            "min": 3.5959208011627197,
            "max": 3.9827582836151123,
            "count": 10
        },
        "TankA2.Policy.Entropy.sum": {
            "value": 180069.328125,
            "min": 180069.328125,
            "max": 200766.859375,
            "count": 10
        },
        "TankA2.Environment.EpisodeLength.mean": {
            "value": 7.298804780876494,
            "min": 6.950023873945567,
            "max": 20.709302325581394,
            "count": 10
        },
        "TankA2.Environment.EpisodeLength.sum": {
            "value": 43968.0,
            "min": 43667.0,
            "max": 48087.0,
            "count": 10
        },
        "TankA2.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.791267991065979,
            "min": 0.30065101385116577,
            "max": 0.8000243902206421,
            "count": 10
        },
        "TankA2.Policy.ExtrinsicValueEstimate.sum": {
            "value": 4767.3896484375,
            "min": 695.40576171875,
            "max": 5024.953125,
            "count": 10
        },
        "TankA2.Environment.CumulativeReward.mean": {
            "value": 0.8156240093998026,
            "min": -0.08105409616324218,
            "max": 0.8359833242698486,
            "count": 10
        },
        "TankA2.Environment.CumulativeReward.sum": {
            "value": 4914.134656633811,
            "min": -187.47812442557915,
            "max": 5250.811259738919,
            "count": 10
        },
        "TankA2.Policy.ExtrinsicReward.mean": {
            "value": 0.8156240093998026,
            "min": -0.08105409616324218,
            "max": 0.8359833242698486,
            "count": 10
        },
        "TankA2.Policy.ExtrinsicReward.sum": {
            "value": 4914.134656633811,
            "min": -187.47812442557915,
            "max": 5250.811259738919,
            "count": 10
        },
        "TankA2.Losses.PolicyLoss.mean": {
            "value": 0.02091867762772987,
            "min": 0.020068403139399987,
            "max": 0.02519464615577211,
            "count": 10
        },
        "TankA2.Losses.PolicyLoss.sum": {
            "value": 0.10459338813864935,
            "min": 0.08027361255759995,
            "max": 0.12597323077886055,
            "count": 10
        },
        "TankA2.Losses.ValueLoss.mean": {
            "value": 0.047508081607520576,
            "min": 0.047508081607520576,
            "max": 0.20563329321642718,
            "count": 10
        },
        "TankA2.Losses.ValueLoss.sum": {
            "value": 0.23754040803760287,
            "min": 0.23754040803760287,
            "max": 0.8225331728657087,
            "count": 10
        },
        "TankA2.Policy.LearningRate.mean": {
            "value": 1.4334695221800004e-05,
            "min": 1.4334695221800004e-05,
            "max": 0.0002844696051767999,
            "count": 10
        },
        "TankA2.Policy.LearningRate.sum": {
            "value": 7.167347610900002e-05,
            "min": 7.167347610900002e-05,
            "max": 0.0012826230724589994,
            "count": 10
        },
        "TankA2.Policy.Epsilon.mean": {
            "value": 0.10477820000000002,
            "min": 0.10477820000000002,
            "max": 0.19482320000000003,
            "count": 10
        },
        "TankA2.Policy.Epsilon.sum": {
            "value": 0.5238910000000001,
            "min": 0.5238910000000001,
            "max": 0.9275410000000001,
            "count": 10
        },
        "TankA2.Policy.Beta.mean": {
            "value": 0.0002484321800000001,
            "min": 0.0002484321800000001,
            "max": 0.0047416776800000004,
            "count": 10
        },
        "TankA2.Policy.Beta.sum": {
            "value": 0.0012421609000000005,
            "min": 0.0012421609000000005,
            "max": 0.021384295900000003,
            "count": 10
        },
        "TankA2.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "TankA2.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "TankA3.Policy.Entropy.mean": {
            "value": 3.4628214836120605,
            "min": 3.4542479515075684,
            "max": 4.145018100738525,
            "count": 10
        },
        "TankA3.Policy.Entropy.sum": {
            "value": 173466.578125,
            "min": 172539.6875,
            "max": 207864.359375,
            "count": 10
        },
        "TankA3.Environment.EpisodeLength.mean": {
            "value": 6.051339915373766,
            "min": 6.051339915373766,
            "max": 23.20135527589545,
            "count": 10
        },
        "TankA3.Environment.EpisodeLength.sum": {
            "value": 42904.0,
            "min": 42904.0,
            "max": 47934.0,
            "count": 10
        },
        "TankA3.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.8520702719688416,
            "min": -0.2793470025062561,
            "max": 0.8520702719688416,
            "count": 10
        },
        "TankA3.Policy.ExtrinsicValueEstimate.sum": {
            "value": 6041.17822265625,
            "min": -576.8515625,
            "max": 6041.17822265625,
            "count": 10
        },
        "TankA3.Environment.CumulativeReward.mean": {
            "value": 0.8655727838031243,
            "min": -0.6491115929898887,
            "max": 0.8655727838031243,
            "count": 10
        },
        "TankA3.Environment.CumulativeReward.sum": {
            "value": 6136.911037164151,
            "min": -1340.4154395241203,
            "max": 6136.911037164151,
            "count": 10
        },
        "TankA3.Policy.ExtrinsicReward.mean": {
            "value": 0.8655727838031243,
            "min": -0.6491115929898887,
            "max": 0.8655727838031243,
            "count": 10
        },
        "TankA3.Policy.ExtrinsicReward.sum": {
            "value": 6136.911037164151,
            "min": -1340.4154395241203,
            "max": 6136.911037164151,
            "count": 10
        },
        "TankA3.Losses.PolicyLoss.mean": {
            "value": 0.02182865243249883,
            "min": 0.021065480473140875,
            "max": 0.024989640712738036,
            "count": 10
        },
        "TankA3.Losses.PolicyLoss.sum": {
            "value": 0.10914326216249415,
            "min": 0.09070549116004259,
            "max": 0.12494820356369019,
            "count": 10
        },
        "TankA3.Losses.ValueLoss.mean": {
            "value": 0.026576081042488413,
            "min": 0.026576081042488413,
            "max": 0.43362333749731374,
            "count": 10
        },
        "TankA3.Losses.ValueLoss.sum": {
            "value": 0.13288040521244207,
            "min": 0.13288040521244207,
            "max": 1.734493349989255,
            "count": 10
        },
        "TankA3.Policy.LearningRate.mean": {
            "value": 1.4334695221800004e-05,
            "min": 1.4334695221800004e-05,
            "max": 0.0002844696051767999,
            "count": 10
        },
        "TankA3.Policy.LearningRate.sum": {
            "value": 7.167347610900002e-05,
            "min": 7.167347610900002e-05,
            "max": 0.0012826230724589994,
            "count": 10
        },
        "TankA3.Policy.Epsilon.mean": {
            "value": 0.10477820000000002,
            "min": 0.10477820000000002,
            "max": 0.19482320000000003,
            "count": 10
        },
        "TankA3.Policy.Epsilon.sum": {
            "value": 0.5238910000000001,
            "min": 0.5238910000000001,
            "max": 0.9275410000000001,
            "count": 10
        },
        "TankA3.Policy.Beta.mean": {
            "value": 0.0002484321800000001,
            "min": 0.0002484321800000001,
            "max": 0.0047416776800000004,
            "count": 10
        },
        "TankA3.Policy.Beta.sum": {
            "value": 0.0012421609000000005,
            "min": 0.0012421609000000005,
            "max": 0.021384295900000003,
            "count": 10
        },
        "TankA3.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "TankA3.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "TankA1.Policy.Entropy.mean": {
            "value": 3.4952821731567383,
            "min": 3.4952821731567383,
            "max": 3.666083812713623,
            "count": 10
        },
        "TankA1.Policy.Entropy.sum": {
            "value": 175595.984375,
            "min": 175249.578125,
            "max": 183846.765625,
            "count": 10
        },
        "TankA1.Environment.EpisodeLength.mean": {
            "value": 11.637512639029323,
            "min": 10.124721603563474,
            "max": 13.876822374293365,
            "count": 10
        },
        "TankA1.Environment.EpisodeLength.sum": {
            "value": 46038.0,
            "min": 45460.0,
            "max": 46913.0,
            "count": 10
        },
        "TankA1.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.691682755947113,
            "min": 0.6069256067276001,
            "max": 0.7433900237083435,
            "count": 10
        },
        "TankA1.Policy.ExtrinsicValueEstimate.sum": {
            "value": 2736.296875,
            "min": 2039.27001953125,
            "max": 3339.307861328125,
            "count": 10
        },
        "TankA1.Environment.CumulativeReward.mean": {
            "value": 0.7501915763236815,
            "min": 0.561626868510586,
            "max": 0.7619481438016776,
            "count": 10
        },
        "TankA1.Environment.CumulativeReward.sum": {
            "value": 2967.757875936484,
            "min": 1887.0662781955689,
            "max": 3416.766278529445,
            "count": 10
        },
        "TankA1.Policy.ExtrinsicReward.mean": {
            "value": 0.7501915763236815,
            "min": 0.561626868510586,
            "max": 0.7619481438016776,
            "count": 10
        },
        "TankA1.Policy.ExtrinsicReward.sum": {
            "value": 2967.757875936484,
            "min": 1887.0662781955689,
            "max": 3416.766278529445,
            "count": 10
        },
        "TankA1.Losses.PolicyLoss.mean": {
            "value": 0.022915956755168734,
            "min": 0.021659239439759406,
            "max": 0.02524679411823551,
            "count": 10
        },
        "TankA1.Losses.PolicyLoss.sum": {
            "value": 0.11457978377584367,
            "min": 0.08663695775903762,
            "max": 0.12623397059117755,
            "count": 10
        },
        "TankA1.Losses.ValueLoss.mean": {
            "value": 0.022868377634634576,
            "min": 0.018056648876518012,
            "max": 0.05353150852024555,
            "count": 10
        },
        "TankA1.Losses.ValueLoss.sum": {
            "value": 0.11434188817317288,
            "min": 0.0875556455925107,
            "max": 0.2141260340809822,
            "count": 10
        },
        "TankA1.Policy.LearningRate.mean": {
            "value": 1.4334695221800004e-05,
            "min": 1.4334695221800004e-05,
            "max": 0.0002844696051767999,
            "count": 10
        },
        "TankA1.Policy.LearningRate.sum": {
            "value": 7.167347610900002e-05,
            "min": 7.167347610900002e-05,
            "max": 0.0012826230724589994,
            "count": 10
        },
        "TankA1.Policy.Epsilon.mean": {
            "value": 0.10477820000000002,
            "min": 0.10477820000000002,
            "max": 0.19482320000000003,
            "count": 10
        },
        "TankA1.Policy.Epsilon.sum": {
            "value": 0.5238910000000001,
            "min": 0.5238910000000001,
            "max": 0.9275410000000001,
            "count": 10
        },
        "TankA1.Policy.Beta.mean": {
            "value": 0.0002484321800000001,
            "min": 0.0002484321800000001,
            "max": 0.0047416776800000004,
            "count": 10
        },
        "TankA1.Policy.Beta.sum": {
            "value": 0.0012421609000000005,
            "min": 0.0012421609000000005,
            "max": 0.021384295900000003,
            "count": 10
        },
        "TankA1.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "TankA1.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1617008910",
        "python_version": "3.8.7 (tags/v3.8.7:6503f05, Dec 21 2020, 17:59:51) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Project\\UNITY\\ml-agents\\ML-tanks\\mlagents\\Scripts\\mlagents-learn --run-id=test --initialize-from=test2 --force",
        "mlagents_version": "0.25.0",
        "mlagents_envs_version": "0.25.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.20.1",
        "end_time_seconds": "1617015647"
    },
    "total": 6736.7505621,
    "count": 1,
    "self": 0.0040958999989015865,
    "children": {
        "run_training.setup": {
            "total": 0.02573420000000004,
            "count": 1,
            "self": 0.02573420000000004
        },
        "TrainerController.start_learning": {
            "total": 6736.720732000001,
            "count": 1,
            "self": 3.5340334998891194,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.004594099999998,
                    "count": 1,
                    "self": 8.004594099999998
                },
                "TrainerController.advance": {
                    "total": 6724.8421708001115,
                    "count": 149827,
                    "self": 1.6342146000224602,
                    "children": {
                        "env_step": {
                            "total": 6723.207956200089,
                            "count": 149827,
                            "self": 5891.571265000108,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 829.8986049000048,
                                    "count": 149827,
                                    "self": 8.863575100067465,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 821.0350297999373,
                                            "count": 166752,
                                            "self": 203.8262756000936,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 617.2087541998437,
                                                    "count": 166752,
                                                    "self": 617.2087541998437
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.7380862999764428,
                                    "count": 149827,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 6725.328326400174,
                                            "count": 149827,
                                            "is_parallel": true,
                                            "self": 1176.047837900067,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0020117000000006158,
                                                    "count": 3,
                                                    "is_parallel": true,
                                                    "self": 0.0005600999999995082,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0014516000000011076,
                                                            "count": 18,
                                                            "is_parallel": true,
                                                            "self": 0.0014516000000011076
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 5549.278476800107,
                                                    "count": 149827,
                                                    "is_parallel": true,
                                                    "self": 19.536352399547468,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 58.06608469997872,
                                                            "count": 149827,
                                                            "is_parallel": true,
                                                            "self": 58.06608469997872
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 5328.150101900164,
                                                            "count": 149827,
                                                            "is_parallel": true,
                                                            "self": 5328.150101900164
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 143.52593780041553,
                                                            "count": 449481,
                                                            "is_parallel": true,
                                                            "self": 46.88481920048797,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 96.64111859992757,
                                                                    "count": 2696886,
                                                                    "is_parallel": true,
                                                                    "self": 96.64111859992757
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 5.090000013296958e-05,
                    "count": 1,
                    "self": 5.090000013296958e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 20173.5844334,
                                    "count": 1291583,
                                    "is_parallel": true,
                                    "self": 29.20109430023149,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 19029.396855999767,
                                            "count": 1291583,
                                            "is_parallel": true,
                                            "self": 19028.376571899767,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 1.0202841000000262,
                                                    "count": 3,
                                                    "is_parallel": true,
                                                    "self": 1.0202841000000262
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 1114.986483100001,
                                            "count": 144,
                                            "is_parallel": true,
                                            "self": 273.5888543000335,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 841.3976287999674,
                                                    "count": 4320,
                                                    "is_parallel": true,
                                                    "self": 841.3976287999674
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.33988270000008924,
                    "count": 1,
                    "self": 0.02269210000122257,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.3171905999988667,
                            "count": 3,
                            "self": 0.3171905999988667
                        }
                    }
                }
            }
        }
    }
}